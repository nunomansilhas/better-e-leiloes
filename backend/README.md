# E-Leiloes API Backend

Backend API para recolha e disponibilizaÃ§Ã£o de dados do **e-leiloes.pt**.

## ğŸ†• VersÃ£o 12.4 (Dezembro 2024)

### ğŸ¯ Novidades

**Backend:**
- âœ… Filtro por `tipo_evento` (imovel/movel) no endpoint `/api/events`
- âœ… Schema completo: valores de leilÃ£o, GPS, tipologia, matrÃ­cula
- âœ… Endpoint DELETE `/api/database` para gestÃ£o de dados
- âœ… Two-phase scraping: listing + details (otimizado)
- âœ… Suporte completo para mÃ³veis e imÃ³veis

**Frontend (ExtensÃ£o):**
- ğŸ¨ Ãcones melhorados: `â˜°` lista, `â–¦` grelha
- ğŸ” Filtros por tipo de evento funcionais
- ğŸ“Š Modal com visualizaÃ§Ã£o lista/grelha
- ğŸ—‘ï¸ GestÃ£o de base de dados integrada
- âš¡ Cards compactos responsivos

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ExtensÃ£o      â”‚â”€â”€â”€â”€â”€â–¶â”‚   FastAPI        â”‚â”€â”€â”€â”€â”€â–¶â”‚   e-leiloes.pt  â”‚
â”‚   (Frontend)    â”‚      â”‚   (Backend)      â”‚      â”‚   (Scraping)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚   SQLite DB  â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â”‚
                                â–¼
                         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                         â”‚ Redis Cache  â”‚
                         â”‚  (Opcional)  â”‚
                         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## âœ¨ Features

- âœ… **API RESTful** com FastAPI
- âœ… **Scraping assÃ­ncrono** com Playwright (two-phase: listing + details)
- âœ… **Base de dados** SQLite com schema completo (valores, GPS, detalhes)
- âœ… **Cache** Redis (opcional, fallback para memÃ³ria)
- âœ… **Processamento em background** para scraping massivo
- âœ… **PaginaÃ§Ã£o e filtros** avanÃ§ados (tipo_evento, distrito, tipo)
- âœ… **CORS** configurado para extensÃ£o browser
- âœ… **DocumentaÃ§Ã£o automÃ¡tica** (Swagger/OpenAPI)
- âœ… **GestÃ£o de base de dados** (delete all, stats)
- âœ… **Suporte completo** para imÃ³veis e mÃ³veis

## ğŸ“‹ PrÃ©-requisitos

- Python 3.10+
- pip
- (Opcional) Redis para caching

## ğŸš€ InstalaÃ§Ã£o

### 1. Clone e instale dependÃªncias

```bash
cd backend
pip install -r requirements.txt
```

### 2. Instale Playwright browsers

```bash
playwright install chromium
```

### 3. Configure variÃ¡veis de ambiente

```bash
cp .env.example .env
# Edita .env com tuas configuraÃ§Ãµes
```

### 4. Inicie o servidor

```bash
python main.py
```

A API estarÃ¡ disponÃ­vel em: **http://localhost:8000**

DocumentaÃ§Ã£o interativa: **http://localhost:8000/docs**

## ğŸ“š Endpoints da API

### GET `/`
Health check da API

### GET `/api/events/{reference}`
ObtÃ©m dados de um evento especÃ­fico.

**Exemplo:**
```bash
curl http://localhost:8000/api/events/NP-2024-12345
```

**Resposta:**
```json
{
  "reference": "NP-2024-12345",
  "tipoEvento": "imovel",
  "valores": {
    "valorBase": 150000.0,
    "valorAbertura": 140000.0,
    "valorMinimo": 130000.0,
    "lanceAtual": 155000.0
  },
  "gps": {
    "latitude": 38.7223,
    "longitude": -9.1393
  },
  "detalhes": {
    "tipo": "Apartamento",
    "subtipo": "Apartamento T2",
    "tipologia": "T2",
    "areaPrivativa": 85.5,
    "areaDependente": 10.0,
    "areaTotal": 95.5,
    "distrito": "Lisboa",
    "concelho": "Lisboa",
    "freguesia": "Avenidas Novas",
    "matricula": null
  },
  "scraped_at": "2024-12-05T10:30:00Z",
  "updated_at": null
}
```

### GET `/api/events`
Lista eventos com paginaÃ§Ã£o e filtros.

**Query params:**
- `page`: NÃºmero da pÃ¡gina (default: 1)
- `limit`: Resultados por pÃ¡gina (default: 50, max: 200)
- `tipo`: Filtrar por tipo de propriedade (Apartamento, Moradia, etc) (opcional)
- `tipo_evento`: Filtrar por tipo de evento - "imovel" ou "movel" (opcional)
- `distrito`: Filtrar por distrito (opcional)

**Exemplos:**
```bash
# Apenas imÃ³veis
curl "http://localhost:8000/api/events?tipo_evento=imovel&page=1&limit=10"

# Apartamentos em Lisboa
curl "http://localhost:8000/api/events?tipo=Apartamento&distrito=Lisboa"

# Apenas mÃ³veis
curl "http://localhost:8000/api/events?tipo_evento=movel"
```

### POST `/api/scrape/event/{reference}`
ForÃ§a re-scraping de um evento especÃ­fico (background task).

### POST `/api/scrape/all`
Inicia scraping de TODOS os eventos (âš ï¸ pode demorar horas!).

**Query params:**
- `max_pages`: Limitar nÃºmero de pÃ¡ginas (opcional)

### GET `/api/scrape/status`
Status atual do scraper.

### DELETE `/api/cache`
Limpa todo o cache Redis/memÃ³ria.

### DELETE `/api/database`
**âš ï¸ PERIGO:** Apaga TODOS os eventos da base de dados.

**Resposta:**
```json
{
  "message": "Base de dados limpa com sucesso",
  "deleted_events": 24
}
```

### GET `/api/stats`
EstatÃ­sticas da base de dados.

**Resposta:**
```json
{
  "total_events": 24,
  "with_gps": 12,
  "by_type": {
    "Apartamento": 8,
    "Moradia": 4,
    "AutomÃ³vel": 12
  }
}
```

## ğŸ”§ ConfiguraÃ§Ã£o

### `.env` principais variÃ¡veis:

```env
# API
API_HOST=0.0.0.0
API_PORT=8000

# Database
DATABASE_URL=sqlite+aiosqlite:///./eleiloes.db

# Redis (opcional)
REDIS_URL=redis://localhost:6379

# CORS
ALLOWED_ORIGINS=http://localhost:3000,https://www.e-leiloes.pt

# Scraping
SCRAPE_DELAY=0.8  # Delay entre requests (segundos)
CONCURRENT_REQUESTS=4  # Requests paralelos
```

## ğŸ“Š Base de Dados

SQLite schema automÃ¡tico:

```sql
CREATE TABLE events (
    reference TEXT PRIMARY KEY,
    tipo_evento TEXT NOT NULL,  -- 'imovel' ou 'movel'
    
    -- Valores do leilÃ£o
    valor_base REAL,
    valor_abertura REAL,
    valor_minimo REAL,
    lance_atual REAL,
    
    -- GPS (apenas imÃ³veis)
    latitude REAL,
    longitude REAL,
    
    -- Detalhes gerais
    tipo TEXT,
    subtipo TEXT,
    
    -- Detalhes imÃ³veis
    tipologia TEXT,
    area_privativa REAL,
    area_dependente REAL,
    area_total REAL,
    
    -- LocalizaÃ§Ã£o
    distrito TEXT,
    concelho TEXT,
    freguesia TEXT,
    
    -- Detalhes mÃ³veis
    matricula TEXT,
    
    -- Metadados
    scraped_at DATETIME,
    updated_at DATETIME
);
```

## ğŸ³ Deploy com Docker

```dockerfile
# Dockerfile (criar)
FROM python:3.11-slim

WORKDIR /app

COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt
RUN playwright install --with-deps chromium

COPY . .

CMD ["python", "main.py"]
```

```bash
docker build -t eleiloes-api .
docker run -p 8000:8000 --env-file .env eleiloes-api
```

## âš¡ Performance & Scraping

### Two-Phase Scraping Strategy

O scraper usa uma estratÃ©gia em duas fases:

**Fase 1 - Listing (tipo=1 e tipo=2):**
- Navega pelas pÃ¡ginas de listagem (imoveis e moveis)
- Extrai referÃªncias e valores dos cards
- Para automaticamente em pÃ¡ginas vazias
- ~2 pÃ¡ginas por tipo = 4 pÃ¡ginas totais

**Fase 2 - Details:**
- Processa cada evento individualmente
- Extrai GPS (imÃ³veis), tipologia, Ã¡reas, localizaÃ§Ã£o
- Processa 4 eventos em paralelo
- Total: ~24 eventos em 2 minutos

### OtimizaÃ§Ãµes

- **Cache Redis**: Reduz latÃªncia de ~800ms para <10ms
- **Processamento paralelo**: 4 eventos simultÃ¢neos (configurÃ¡vel)
- **Delay configurÃ¡vel**: Evita sobrecarga do site (800ms default)
- **Background tasks**: Scraping massivo sem bloquear API
- **Stop on empty**: Para navegaÃ§Ã£o em pÃ¡ginas vazias automaticamente

## ğŸ”’ SeguranÃ§a

- **CORS** restrito aos domÃ­nios configurados
- **Rate limiting** (TODO: adicionar)
- **API Key** (TODO: adicionar autenticaÃ§Ã£o)

## ğŸ“ Logs

Logs estruturados no stdout:
```
ğŸš€ Iniciando E-Leiloes API...
âœ… Database inicializada
âœ… Redis conectado
âœ… API pronta!
```

## ğŸ§ª Testes

```bash
# Teste unitÃ¡rio
pytest

# Teste de carga
locust -f tests/load_test.py
```

## ğŸ“ˆ MonitorizaÃ§Ã£o

IntegraÃ§Ã£o com:
- Prometheus (mÃ©tricas)
- Grafana (dashboards)
- Sentry (error tracking)

## ğŸ¤ IntegraÃ§Ã£o com ExtensÃ£o

A extensÃ£o Tampermonkey (`betterE-Leiloes-v12.4-API.user.js`) faz requests para:

```javascript
const API_URL = 'http://localhost:8000/api';

// Buscar evento especÃ­fico
async function getEventData(reference) {
    const response = await fetch(`${API_URL}/events/${reference}`);
    return await response.json();
}

// Listar eventos com filtros
async function listEvents(page = 1, limit = 50, filters = {}) {
    let url = `${API_URL}/events?page=${page}&limit=${limit}`;
    
    if (filters.tipoEvento) url += `&tipo_evento=${filters.tipoEvento}`;
    if (filters.distrito) url += `&distrito=${filters.distrito}`;
    
    const response = await fetch(url);
    return await response.json();
}

// Trigger scraping completo
async function triggerFullScrape() {
    const response = await fetch(`${API_URL}/scrape/all`, { method: 'POST' });
    return await response.json();
}

// Limpar base de dados
async function clearDatabase() {
    const response = await fetch(`${API_URL}/database`, { method: 'DELETE' });
    return await response.json();
}
```

### Features da ExtensÃ£o v12.4

- ğŸ¨ **Badges nos cards**: GPS, Valores, Detalhes
- ğŸ“Š **Modal de visualizaÃ§Ã£o**: Lista e grelha compacta
- ğŸ” **Filtros avanÃ§ados**: Por tipo de evento (imÃ³vel/mÃ³vel) e distrito
- ğŸ—‘ï¸ **GestÃ£o de dados**: Limpar base de dados com confirmaÃ§Ã£o dupla
- ğŸ“ˆ **EstatÃ­sticas**: Total de eventos, GPS, tipos
- âš¡ **Scraping em background**: Com polling de status

## ğŸ› Troubleshooting

**Erro: "playwright not installed"**
```bash
playwright install chromium
```

**Erro: "Redis connection failed"**
- Verifica se Redis estÃ¡ a correr: `redis-cli ping`
- Ou desativa Redis no `.env` (usa cache em memÃ³ria)

**Scraping muito lento**
- Aumenta `CONCURRENT_REQUESTS` no `.env`
- Reduz `SCRAPE_DELAY` (cuidado com rate limiting)

## ğŸ“„ LicenÃ§a

MIT License

## ğŸ‘¨â€ğŸ’» Autor

Nuno Mansilhas
